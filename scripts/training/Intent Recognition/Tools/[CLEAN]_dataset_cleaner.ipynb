{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CSV Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_train = r\"../datasets/Conversational Training/\"\n",
    "health_monitor = r\"../datasets/Health Monitoring/\"\n",
    "mh_predict = r\"../datasets/Mental Health Prediction/\"\n",
    "\n",
    "loc_1, loc_2 = os.path.join(conv_train, os.listdir(conv_train)[0]), os.path.join(conv_train, os.listdir(conv_train)[1])\n",
    "\n",
    "print(loc_1, loc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, csv\n",
    "\n",
    "def remove_special_characters(text):\n",
    "  cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,!?;:\\'\"-]+', '', text)\n",
    "  return cleaned_text\n",
    "\n",
    "input_file = loc_2\n",
    "output_file = \"output.csv\"\n",
    "with open(input_file, 'r', encoding='utf-8') as infile, \\\n",
    "     open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    for row in reader:\n",
    "        cleaned_row = []\n",
    "        for cell in row:\n",
    "            cleaned_cell = remove_special_characters(cell)\n",
    "            cleaned_row.append(cleaned_cell)\n",
    "        writer.writerow(cleaned_row)\n",
    "\n",
    "print(f\"Cleaned data written to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV cleaning (grouping, sorting, and comment labelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_loc_x = r\"C:\\Users\\parvs\\VSC Codes\\Python-root\\_Projects_Personal\\mindEase_v2\\scripts\\training\\Intent Recognition\\Mediatory Saves\\processed_dataset.csv\"\n",
    "df = pd.read_csv(file_loc_x, header=0, names=[\"text\", \"label\"])\n",
    "\n",
    "label_counts = df['label'].value_counts().reset_index()\n",
    "label_counts.columns = ['label', 'total_amount']\n",
    "\n",
    "sorted_labels = label_counts.sort_values(by='total_amount', ascending=True)['label']\n",
    "modified_data = []\n",
    "\n",
    "for label in sorted_labels:\n",
    "    group = df[df['label'] == label]\n",
    "    modified_data.extend(group.values.tolist())  # Add patterns for the label\n",
    "    modified_data.append([None, None])  # Add a gap after each group\n",
    "\n",
    "modified_df = pd.DataFrame(modified_data, columns=[\"text\", \"label\"])\n",
    "modified_df.to_csv(\"your_modified_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Labels in DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "file_loc_x = r\"C:\\Users\\parvs\\VSC Codes\\Python-root\\_Projects_Personal\\mindEase_v2\\scripts\\training\\Intent Recognition\\Mediatory Saves\\your_modified_dataset.csv\"\n",
    "df = pd.read_csv(file_loc_x, header=0, names=[\"text\", \"label\"])\n",
    "\n",
    "label_counts = df['label'].value_counts().reset_index()\n",
    "label_counts.columns = ['label', 'total_amount']\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "sorted_label_counts = label_counts.sort_values(by='total_amount', ascending=True)\n",
    "\n",
    "pprint(sorted_label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Load the CSV into a Pandas DataFrame\n",
    "file_loc_x = r\"C:\\Users\\parvs\\VSC Codes\\Python-root\\_Projects_Personal\\mindEase_v2\\scripts\\training\\Intent Recognition\\Mediatory Saves\\your_modified_dataset.csv\"\n",
    "df = pd.read_csv(file_loc_x, header=0, names=[\"text\", \"label\"])\n",
    "\n",
    "# Clean the labels: remove preceding/trailing spaces and convert to lowercase\n",
    "df['label'] = df['label'].str.strip().str.lower()\n",
    "\n",
    "# Count the total occurrences of each label\n",
    "label_counts = df['label'].value_counts().reset_index()\n",
    "label_counts.columns = ['label', 'total_amount']\n",
    "\n",
    "# Create a new DataFrame to store the processed data\n",
    "processed_df = pd.DataFrame(columns=[\"text\", \"label\"])\n",
    "\n",
    "# Process labels with more than 20 entries\n",
    "for label in label_counts['label']:\n",
    "    count = label_counts[label_counts['label'] == label]['total_amount'].values[0]\n",
    "    if count > 20:\n",
    "        # Randomly sample 20 entries for labels with more than 20 entries\n",
    "        sampled_df = df[df['label'] == label].sample(n=20, random_state=42)\n",
    "        processed_df = pd.concat([processed_df, sampled_df], ignore_index=True)\n",
    "    elif count < 20:\n",
    "        # Print labels with fewer than 20 entries\n",
    "        print(f\"{label}: {20-count}\")\n",
    "        processed_df = pd.concat([processed_df, df[df['label'] == label]], ignore_index=True)\n",
    "\n",
    "# Reset index of the DataFrame\n",
    "processed_df = processed_df.reset_index(drop=True)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "processed_df.to_csv(r\"C:\\Users\\parvs\\VSC Codes\\Python-root\\_Projects_Personal\\mindEase_v2\\datasets\\Intent Training\\balanced_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Dataset processed and saved to 'balanced_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to remove all the rows with \"#\" (comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\parvs\\VSC Codes\\Python-root\\_Projects_Personal\\mindEase_v2\\scripts\\training\\Intent Recognition\\Mediatory Saves\\processed_dataset.csv\")\n",
    "\n",
    "df = df[~df[\"text\"].str.startswith(\"#\", na=False)]\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\parvs\\VSC Codes\\Python-root\\_Projects_Personal\\mindEase_v2\\scripts\\training\\Intent Recognition\\Mediatory Saves\\processed_dataset.csv\", index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
